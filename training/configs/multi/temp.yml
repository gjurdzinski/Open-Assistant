model_name: microsoft/deberta-v3-base
learning_rate: 5e-5
scheduler: constant
gradient_checkpointing: true
gradient_accumulation_steps: 6
per_device_train_batch_size: 1
per_device_eval_batch_size: 1 # 4
warmup_steps: 0
eval_steps: 50
save_steps: 50
max_length: 1 # 4096
num_train_epochs: 1 # 3
auto_find_batch_size: false
metric: InformativenessRating
write_bucketised_predictions: true
raw_dataset_path: "/mnt/ml-team/homes/grzegorz.jurdzinski/datasets/newsroom/newsroom-aggregated-sorted-order.csv"
report_to:
  - tensorboard
# summeval_path: /root/datasets/sensitivity_equal_chunks/InformativenessRating_dataset/
summeval_path: /mnt/ml-team/homes/grzegorz.jurdzinski/datasets/sensitivity_equal_chunks/InformativenessRating_dataset/
output_dirs:
  - ./runs/to_delete/
train_splits:
  - []
datasets:
  - newsroom_local
