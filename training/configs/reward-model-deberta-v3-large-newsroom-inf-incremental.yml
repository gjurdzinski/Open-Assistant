model_name: OpenAssistant/reward-model-deberta-v3-large
learning_rate: 5e-5
scheduler: cosine
gradient_checkpointing: false
gradient_accumulation_steps: 16
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
warmup_steps: 100
eval_steps: 50
save_steps: 50
max_length: 3072
num_train_epochs: 5
report_to:
  - tensorboard
summeval_path: /root/datasets/InformativenessRating_dataset/
output_dirs:
  - ./incremental/inf/large/train_0_2/
  - ./incremental/inf/large/train_0_3/
  - ./incremental/inf/large/train_0_4/
  - ./incremental/inf/large/train_0_5/
  - ./incremental/inf/large/train_0_6/
  - ./incremental/inf/large/train_0_7/
  - ./incremental/inf/large/train_0_8/
  - ./incremental/inf/large/train_0_9/
train_splits:
  - [train_0, train_1, train_2]
  - [train_0, train_1, train_2, train_3]
  - [train_0, train_1, train_2, train_3, train_4]
  - [train_0, train_1, train_2, train_3, train_4, train_5]
  - [train_0, train_1, train_2, train_3, train_4, train_5, train_6]
  - [train_0, train_1, train_2, train_3, train_4, train_5, train_6, train_7]
  - [train_0, train_1, train_2, train_3, train_4, train_5, train_6, train_7, train_8]
  - [train_0, train_1, train_2, train_3, train_4, train_5, train_6, train_7, train_8, train_9]
datasets:
  - newsroom_local
