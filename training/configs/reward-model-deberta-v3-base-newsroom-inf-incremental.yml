model_name: OpenAssistant/reward-model-deberta-v3-base
learning_rate: 5e-5
scheduler: cosine
gradient_checkpointing: false
gradient_accumulation_steps: 16
per_device_train_batch_size: 1
per_device_eval_batch_size: 4
warmup_steps: 100
eval_steps: 50
save_steps: 50
max_length: 4096
num_train_epochs: 5
report_to:
  - tensorboard
summeval_path: /root/datasets/InformativenessRating_dataset/
output_dirs:
  - ./incremental/inf/train_0/
  - ./incremental/inf/train_0_1/
  - ./incremental/inf/train_0_2/
  - ./incremental/inf/train_0_3/
  - ./incremental/inf/train_0_4/
  - ./incremental/inf/train_0_5/
  - ./incremental/inf/train_0_6/
  - ./incremental/inf/train_0_7/
  - ./incremental/inf/train_0_8/
  - ./incremental/inf/train_0_9/
train_splits:
  - [train_0]
  - [train_0, train_1]
  - [train_0, train_1, train_2]
  - [train_0, train_1, train_2, train_3]
  - [train_0, train_1, train_2, train_3, train_4]
  - [train_0, train_1, train_2, train_3, train_4, train_5]
  - [train_0, train_1, train_2, train_3, train_4, train_5, train_6]
  - [train_0, train_1, train_2, train_3, train_4, train_5, train_6, train_7]
  - [train_0, train_1, train_2, train_3, train_4, train_5, train_6, train_7, train_8]
  - [train_0, train_1, train_2, train_3, train_4, train_5, train_6, train_7, train_8, train_9]
datasets:
  - newsroom_local
