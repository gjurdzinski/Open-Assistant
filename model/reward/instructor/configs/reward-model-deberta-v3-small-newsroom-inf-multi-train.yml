model_name: microsoft/deberta-v3-small
learning_rate: 5e-5
scheduler: cosine
gradient_checkpointing: false
gradient_accumulation_steps: 6
per_device_train_batch_size: 1
per_device_eval_batch_size: 3
warmup_steps: 25
eval_steps: 25
save_steps: 25
max_length: 4096
num_train_epochs: 4
summeval_path: ./datasets/sensitivity/InformativenessRating_dataset/
output_dirs:
  - ./models/train0/
  - ./models/train1/
  - ./models/train2/
  - ./models/train3/
  - ./models/train4/
  - ./models/train5/
  - ./models/train6/
  - ./models/train7/
  - ./models/train8/
  - ./models/train9/
train_splits:
  - [train_0]
  - [train_1]
  - [train_2]
  - [train_3]
  - [train_4]
  - [train_5]
  - [train_6]
  - [train_7]
  - [train_8]
  - [train_9]
datasets:
  - newsroom_local