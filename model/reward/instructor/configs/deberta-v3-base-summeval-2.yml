model_name: microsoft/deberta-v3-base
learning_rate: 1e-5
scheduler: cosine
gradient_checkpointing: false
gradient_accumulation_steps: 16
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
warmup_steps: 600
eval_steps: 200
save_steps: 500
max_length: 1024
num_train_epochs: 3
summeval_path: /home/grzegorz.jurdzinski/datasets/summeval_reward_modeling/relevance_dataset.hf
output_dir: /home/grzegorz.jurdzinski/models/deberta-v3-base-summeval-2
datasets:
  - summeval_local
